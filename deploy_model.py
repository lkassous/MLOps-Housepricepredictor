"""
D√©ploiement et pr√©diction avec le mod√®le MLflow
Next Step du Tutorial: Deploy models using MLflow's deployment tools
"""

import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import mlflow
import mlflow.pyfunc
from mlflow.tracking import MlflowClient
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# Configuration
MODEL_NAME = "HousePrices-BestModel"

def load_production_model():
    """Charge le mod√®le en Production depuis le Model Registry"""
    
    print("\n" + "="*70)
    print("üîÑ CHARGEMENT DU MOD√àLE EN PRODUCTION")
    print("="*70)
    
    try:
        # Charger le mod√®le en Production
        model_uri = f"models:/{MODEL_NAME}/Production"
        print(f"\nüì¶ Chargement du mod√®le: {model_uri}")
        
        model = mlflow.pyfunc.load_model(model_uri)
        
        # R√©cup√©rer les informations du mod√®le
        client = MlflowClient()
        model_version = client.get_latest_versions(MODEL_NAME, stages=["Production"])[0]
        
        print(f"‚úì Mod√®le charg√© avec succ√®s")
        print(f"   Version: {model_version.version}")
        print(f"   Run ID: {model_version.run_id}")
        print(f"   Stage: Production")
        print("="*70)
        
        return model, model_version
        
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
        print("\nüí° Assurez-vous qu'un mod√®le est enregistr√© en Production")
        print("   Ex√©cutez 'register_best_model.py' d'abord")
        return None, None

def prepare_test_data():
    """Pr√©pare les donn√©es de test pour les pr√©dictions"""
    
    print("\nüìä Pr√©paration des donn√©es de test...")
    
    try:
        # Charger les donn√©es d'entra√Ænement pour r√©cup√©rer les transformations
        df_train = pd.read_csv('train.csv')
        df_test = pd.read_csv('test.csv')
        
        # Sauvegarder les IDs pour la soumission
        test_ids = df_test['Id'].copy()
        
        # Supprimer les colonnes avec trop de valeurs manquantes (m√™me traitement que l'entra√Ænement)
        threshold = len(df_train) * 0.5
        cols_to_keep = df_train.dropna(thresh=threshold, axis=1).columns
        cols_to_keep = [col for col in cols_to_keep if col in df_test.columns and col != 'SalePrice']
        
        df_test = df_test[cols_to_keep]
        
        # Supprimer la colonne Id
        df_test = df_test.drop(['Id'], axis=1, errors='ignore')
        
        # Identifier les colonnes cat√©gorielles et num√©riques
        categorical_features = df_test.select_dtypes(include=['object']).columns
        numeric_features = df_test.select_dtypes(include=['int64', 'float64']).columns
        
        # Remplir les valeurs manquantes
        for col in numeric_features:
            df_test[col].fillna(df_test[col].median(), inplace=True)
        
        for col in categorical_features:
            df_test[col].fillna(df_test[col].mode()[0] if len(df_test[col].mode()) > 0 else 'Unknown', inplace=True)
        
        # Encoder les variables cat√©gorielles
        for col in categorical_features:
            le = LabelEncoder()
            # Fit sur train et test combin√©s pour √©viter les erreurs
            combined = pd.concat([df_train[col].astype(str), df_test[col].astype(str)])
            le.fit(combined)
            df_test[col] = le.transform(df_test[col].astype(str))
        
        print(f"‚úì Donn√©es de test pr√©par√©es: {df_test.shape[0]} maisons, {df_test.shape[1]} features")
        
        return df_test, test_ids
        
    except FileNotFoundError:
        print("‚ùå Fichier test.csv non trouv√©")
        return None, None
    except Exception as e:
        print(f"‚ùå Erreur lors de la pr√©paration des donn√©es: {e}")
        return None, None

def make_predictions(model, X_test, test_ids):
    """Fait des pr√©dictions sur les donn√©es de test"""
    
    print("\n" + "="*70)
    print("üîÆ PR√âDICTIONS SUR LES DONN√âES DE TEST")
    print("="*70)
    
    try:
        # Faire les pr√©dictions
        print(f"\n‚è≥ Pr√©diction en cours sur {len(X_test)} maisons...")
        predictions = model.predict(X_test)
        
        print(f"‚úì Pr√©dictions termin√©es")
        
        # Statistiques des pr√©dictions
        print("\nüìä Statistiques des pr√©dictions:")
        print(f"   Prix minimum pr√©dit: ${predictions.min():,.2f}")
        print(f"   Prix maximum pr√©dit: ${predictions.max():,.2f}")
        print(f"   Prix moyen pr√©dit: ${predictions.mean():,.2f}")
        print(f"   Prix m√©dian pr√©dit: ${np.median(predictions):,.2f}")
        
        # Cr√©er le DataFrame de soumission
        submission = pd.DataFrame({
            'Id': test_ids,
            'SalePrice': predictions
        })
        
        # Sauvegarder
        output_file = 'my_submission.csv'
        submission.to_csv(output_file, index=False)
        
        print(f"\nüíæ Fichier de soumission cr√©√©: {output_file}")
        print(f"   Format: Id, SalePrice")
        print(f"   Nombre de lignes: {len(submission)}")
        
        # Afficher quelques exemples
        print("\nüìã Aper√ßu des premi√®res pr√©dictions:")
        print(submission.head(10).to_string(index=False))
        
        print("="*70)
        
        return submission
        
    except Exception as e:
        print(f"‚ùå Erreur lors des pr√©dictions: {e}")
        return None

def serve_model_info():
    """Affiche les informations pour servir le mod√®le"""
    
    print("\n" + "="*70)
    print("üöÄ D√âPLOIEMENT DU MOD√àLE")
    print("="*70)
    
    print("\nüìå Options de d√©ploiement MLflow:")
    
    print("\n1Ô∏è‚É£  Servir le mod√®le comme API REST:")
    print("   Commande:")
    print(f"   mlflow models serve -m models:/{MODEL_NAME}/Production -p 5001")
    print("   ")
    print("   Le mod√®le sera accessible sur http://127.0.0.1:5001")
    print("   Endpoint de pr√©diction: POST http://127.0.0.1:5001/invocations")
    
    print("\n2Ô∏è‚É£  Servir avec Docker:")
    print("   Commandes:")
    print(f"   mlflow models build-docker -m models:/{MODEL_NAME}/Production -n house-prices-model")
    print("   docker run -p 5001:8080 house-prices-model")
    
    print("\n3Ô∏è‚É£  Exporter le mod√®le:")
    print("   Python:")
    print(f"   model = mlflow.pyfunc.load_model('models:/{MODEL_NAME}/Production')")
    print("   predictions = model.predict(X_test)")
    
    print("\n4Ô∏è‚É£  Tester l'API (apr√®s avoir lanc√© le serveur):")
    print("   curl -X POST -H 'Content-Type: application/json' \\")
    print("        -d '{\"dataframe_split\": {\"columns\": [...], \"data\": [[...]]}}' \\")
    print("        http://127.0.0.1:5001/invocations")
    
    print("="*70)

def main():
    """Fonction principale"""
    
    print("\n" + "="*70)
    print("D√âPLOIEMENT ET PR√âDICTION - NEXT STEP DU TUTORIAL")
    print("="*70)
    print("\nüéØ Objectif: Charger le mod√®le Production et faire des pr√©dictions")
    
    # Charger le mod√®le
    model, model_version = load_production_model()
    
    if model is None:
        return
    
    # Pr√©parer les donn√©es de test
    X_test, test_ids = prepare_test_data()
    
    if X_test is None:
        return
    
    # Faire des pr√©dictions
    submission = make_predictions(model, X_test, test_ids)
    
    if submission is None:
        return
    
    # Informations de d√©ploiement
    serve_model_info()
    
    print("\n‚úÖ Processus termin√©!")
    print("\nüìå Fichiers cr√©√©s:")
    print("   - my_submission.csv : Pr√©dictions pour le test set")
    print("\nüìå Prochaines √©tapes:")
    print("   1. V√©rifiez my_submission.csv")
    print("   2. (Optionnel) Servez le mod√®le comme API REST")
    print("   3. (Optionnel) Containerisez avec Docker")

if __name__ == "__main__":
    main()
